{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab2-naive-bayes.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UisOuoIAXgT6"},"source":["# Practical Machine Learning\n","# Lab 2"]},{"cell_type":"markdown","metadata":{"id":"YEn9Vd26XgT8"},"source":["## Naive Bayes\n","\n","We are going to classify the MNIST data using the Naive Bayes classifier using the **scikit-learn** library."]},{"cell_type":"markdown","metadata":{"id":"bTjAqTKlXgT8"},"source":["## Bayes' theorem"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"ILstAW8VXgT9"},"source":["![bayes_rule.png](attachment:bayes_rule.png) "]},{"cell_type":"markdown","metadata":{"id":"WuBdJ5xbXgT-"},"source":["## Naive Bayes\n","\n","Naives Bayes method is a supervised learning algorithm based on applying Bayes' theorem with the '*naive*' assumption of conditional independence between every pair of features given the value of the class variable.\n","\n","Let *X* be a feature vector $X=\\{x_1, x_2,..., x_n\\}$ and $y_k$ be a class variable, the predicted label ($y_{hat}$) is:\n","$$y_{hat} = argmax_{y_k} P(y_k) \\prod_{i=1}^{i=n}P(x_i | y_k) $$\n","where $P(y_k)$ is the likelihood of class $y_k$ and $P(x_i | y_k)$ is the likelihood of feature $x_i$ in class $y_k$."]},{"cell_type":"markdown","metadata":{"id":"fQfa0JDCXgT_"},"source":["### Gaussian Naive Bayes\n","\n","The likelihood of the features is assumed to be Gaussian:\n","$$P(x_i | y_k) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_{y_k}}} exp(- \\frac{x_i - \\mu_{y_k}}{2\\sigma^2_{y_k}}) $$\n","\n","where $\\sigma_{y_k} $ and $\\mu_{y_k}$ are estimated using maximum likelihood."]},{"cell_type":"markdown","metadata":{"id":"9fAc7EtyXgT_"},"source":["### Multinomial Naive Bayes\n","\n","It is used for multinomially distributed data and $P(x_i | y_k)$ is the probability of feature $i$ appearing in a sample belonging to class $y_k$.\n","\n","\n","$$P(x_i | y_k) = \\frac{number-of-examples-in-class-y_k-that-have-x_i}{number-of-examples-in-class-y_k}$$\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EpyZVEkJXgUA"},"source":["## How to use scikit-learn"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wzd9zlv_XgUB","executionInfo":{"status":"ok","timestamp":1637515700692,"user_tz":-120,"elapsed":29578,"user":{"displayName":"Anca Mihaela Iordachescu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJ1nT0_jIbKnxh9_26ego2oOW52dl2-asxchXixQ=s64","userId":"07795954950481201957"}},"outputId":"d2bb2bd0-e9ae-462c-aabf-c76171054054"},"source":["# import the library\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","from sklearn.neighbors import KNeighborsClassifier\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"NPPjiRY8XgUE"},"source":["##### define the model\n","model = KNeighborsClassifier(n_neighbors=7, metric='minkowski') \n","\n","##### train the model\n","model.fit(X, y)\n","\n","##### predict the labels\n","predicted_labels = model.predict(X_test)\n","\n","##### compute the accuracy\n","accuracy = model.score(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"ijsH9caAXgUF"},"source":["# Execises"]},{"cell_type":"markdown","metadata":{"id":"GJF-5PlgXgUG"},"source":["### 1. Compute the accuracy of the multinomial naive bayes classifier on the MNIST subset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lF9AnysVXgUG","executionInfo":{"status":"ok","timestamp":1637515994350,"user_tz":-120,"elapsed":366,"user":{"displayName":"Anca Mihaela Iordachescu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJ1nT0_jIbKnxh9_26ego2oOW52dl2-asxchXixQ=s64","userId":"07795954950481201957"}},"outputId":"ce4879d8-0dff-483d-9005-c1bfc39bdc1b"},"source":["# load data\n","import numpy as np\n","train_images = np.load('/content/gdrive/MyDrive/IA/lab2/data/train_images.npy') # load training images\n","train_labels = np.load('/content/gdrive/MyDrive/IA/lab2/data/train_labels.npy') # load training labels\n","test_images = np.load('/content/gdrive/MyDrive/IA/lab2/data/test_images.npy') # load testing images\n","test_labels = np.load('/content/gdrive/MyDrive/IA/lab2/data/test_labels.npy') # load testing labels\n","\n","def accuracy(predicted_labels, test_labels):\n","  return (predicted_labels == test_labels).sum()/predicted_labels.shape[0]\n","\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB\n","model = MultinomialNB()\n","model.fit(train_images, train_labels)\n","predicted_labels = model.predict(test_images)\n","\n","acc = accuracy(predicted_labels, test_labels)\n","print(\"Accuracy: {}\".format(acc))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.846\n"]}]}]}