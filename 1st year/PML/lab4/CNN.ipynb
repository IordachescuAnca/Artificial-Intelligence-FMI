{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"tf2","language":"python","name":"tf2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Lab 4 - CNN - sol.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Rg55q0off0rM","colab_type":"text"},"source":["# Practical Machine Learning\n","# Lab 4\n","## Convolutional Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"XCgc9TYef0rP","colab_type":"text"},"source":["![cnn.jpeg](attachment:cnn.jpeg)\n","A ConvNet arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a ConvNet transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels)"]},{"cell_type":"markdown","metadata":{"id":"p0HB4H-Mf0rQ","colab_type":"text"},"source":["## Properties of the convolution layer\n"," - parameter sharing\n","    - in a fully connected neural network one weight is used only once during a forward step, but in a CNN one weight is used in each position of the input (when the stride is 1, excepting the edges)\n"," - local connectivity\n","     - each neuron (unit) is connected only to a small region, this region is named receptive field\n"," - equivariance to translation\n","     - if a filter learns to recognise a specific pattern, it will recognise that pattern no matter its location in the input\n","     \n","## Properties of the pooling layer\n"," - a pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs\n"," - helps to make the representation approximately invariant to small translations of the input"]},{"cell_type":"code","metadata":{"id":"fZvVTYazf0rS","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sw51FaiKf0rW","colab_type":"text"},"source":["- Loading the images"]},{"cell_type":"code","metadata":{"id":"nFnyDaPJf0rY","colab_type":"code","outputId":"fd661fd8-2b1f-4c12-e450-7fe2fe136acb","colab":{}},"source":["# load the training data\n","train_images_raw = np.load('data/train_images.npy')\n","train_labels = np.load('data/train_labels.npy') \n","print('The number of images for training is %d.' % train_images_raw.shape[0]) \n","\n","# load the test data\n","test_images_raw = np.load('data/test_images.npy')\n","test_labels = np.load('data/test_labels.npy') "],"execution_count":0,"outputs":[{"output_type":"stream","text":["The number of images for training is 10000.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"muqmvcKKf0rc","colab_type":"text"},"source":["###  Prepare the data\n","Convert the data from uint8 to float32, normalize the pixel data from [0, 255] to [0, 1]\n","\n","Compute the mean image and substract it from each training and test image."]},{"cell_type":"code","metadata":{"id":"1auL2Is9f0rd","colab_type":"code","colab":{}},"source":["# write your code here  \n","# TODO: 2.1 convert int to float\n","train_images = np.float32(train_images_raw) / 255\n","test_images = np.float32(test_images_raw) / 255\n","# TODO: 2.2 compute mean training image\n","mean_image = np.mean(train_images, axis=0)\n","# TODO: 2.3 subtract the mean image from training and test data.\n","train_images -= mean_image\n","test_images -= mean_image  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZaMejdSf0rg","colab_type":"text"},"source":["### Define a conv layer"]},{"cell_type":"code","metadata":{"id":"4n-J_W8_f0rh","colab_type":"code","outputId":"0bf649ce-c9fb-4549-a028-9b4f2fa3a806","colab":{}},"source":["import tensorflow.keras.layers as layers\n","layers.Conv2D(filters=64, kernel_size=(5, 5), activation='relu', strides=(1,1), padding='same')\n","# filters - the number of conv filters\n","# kernel_size - the size of the kernel, we usually use odd numbers\n","# activation - the activation function\n","# strides - the stride on each dimension\n","# padding - same or valid"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.layers.convolutional.Conv2D at 0x158e007c3c8>"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"_j-Y4lv5f0rn","colab_type":"text"},"source":["### Define a pooling layer"]},{"cell_type":"code","metadata":{"id":"YCfvL5Pqf0rn","colab_type":"code","outputId":"71b6535c-23d0-4277-cce2-3b95c9100263","colab":{}},"source":["layers.AveragePooling2D(pool_size=3, strides=(2,2), padding='same') # average pooling\n","layers.MaxPool2D(pool_size=3, strides=(2,2), padding='same') # max pooling \n","# pool_size - the size of the window, we usually use odd numbers \n","# strides - the stride on each dimension\n","# padding - same or valid"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23a5b6fd710>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"6TNMjo1Df0rr","colab_type":"text"},"source":["- Flatten layer - it flattens the input, but does not affect the batch size. "]},{"cell_type":"code","metadata":{"id":"TXPCr74Kf0rs","colab_type":"code","outputId":"4a8d4ab1-dcfd-479f-cd21-44e9b0c2382d","colab":{}},"source":["layers.Flatten()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.layers.core.Flatten at 0x23a52e28fd0>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"LLv-6pMof0rx","colab_type":"text"},"source":["## Exercises"]},{"cell_type":"markdown","metadata":{"id":"FeziBO4if0rz","colab_type":"text"},"source":["## 1. Train a convolutional neural network with the following configuration:\n","    - L1: conv\n","        - kernel-size=3, stride=1, padding=same, filters=32, activation-function=relu\n","    - L2: conv\n","        - kernel-size=3, stride=1, padding=same, filters=32, activation-function=relu\n","    - L3: pool\n","        - kernel-size=2, stride=2, padding=same\n","    - L4: conv\n","        - kernel-size=3, stride=1, padding=same, filters=64, activation-function=relu\n","    - L5: conv\n","        - kernel-size=3, stride=1, padding=same, filters=64, activation-function=relu\n","    - L6: pool\n","        - kernel-size=2, stride=2, padding=same\n","    - L7: conv\n","        - kernel-size=3, stride=1, padding=same, filters=128, activation-function=relu\n","    - L8: conv\n","        - kernel-size=3, stride=1, padding=same, filters=128, activation-function=relu\n","    - L9: pool\n","        - kernel-size=2, stride=2, padding=same\n","    - L10: flatten\n","    - L11: dropout\n","        - dropout rate=0.3\n","    - L12 - fully connected (dense) with 10 units and softmax as activation function.\n"," \n","Train the network for 10 epochs using what optimizer you like.\n","\n","The loss you have to use is 'categorical_crossentropy' (you should encode the training labels using one-hot-encoding in order to use this loss).\n","\n","Does this network perform better than a fully connected one?\n","    "]},{"cell_type":"code","metadata":{"id":"K8Q2B8NEf0r1","colab_type":"code","outputId":"e7abfa4c-4063-4bcc-df14-18f36e9f5598","colab":{}},"source":["# write your code here\n","\n","# 1.1 encode the training labels in one-hot\n","labels = np.zeros((len(train_labels), train_labels.max() + 1))\n","for idx, label in enumerate(train_labels):\n","    labels[idx, label] = 1 \n","\n","# 1.2 define the cnn\n","import tensorflow as tf \n","\n","model = tf.keras.models.Sequential([\n","  layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=(1,1), padding='same'),  \n","  layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=(1,1), padding='same'),  \n","  layers.MaxPool2D(pool_size=2, strides=(2, 2), padding='same'),\n","  layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=(1,1), padding='same'),  \n","  layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=(1,1), padding='same'),  \n","  layers.MaxPool2D(pool_size=2, strides=(2, 2), padding='same'),\n","  layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=(1,1), padding='same'),  \n","  layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=(1,1), padding='same'),  \n","  layers.MaxPool2D(pool_size=2, strides=(2, 2), padding='same'),\n","  layers.Flatten(),\n","  layers.Dropout(0.3),  \n","  layers.Dense(10, activation='softmax') \n","  ])\n","# 1.3 compile the cnn\n","from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n","\n","# define the optimizer, set the learning rate and the momentum (for SGD with momentum)\n","optimizer = Adam(lr=0.001)  \n","# compile the model specifying the optimizer, the loss and the metrics (as an array).\n","model.compile(optimizer=optimizer,\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","# 1.4 train the cnn\n","model.fit(train_images[:-1000], labels[:-1000],\n","          epochs=10, batch_size=32, initial_epoch=0, \n","          validation_data=(train_images[-1000:], labels[-1000:]))  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 9000 samples, validate on 1000 samples\n","Epoch 1/10\n","9000/9000 [==============================] - 57s 6ms/sample - loss: 1.8838 - accuracy: 0.2959 - val_loss: 1.5897 - val_accuracy: 0.4080\n","Epoch 2/10\n","9000/9000 [==============================] - 57s 6ms/sample - loss: 1.4958 - accuracy: 0.4534 - val_loss: 1.3947 - val_accuracy: 0.4730\n","Epoch 3/10\n","9000/9000 [==============================] - 60s 7ms/sample - loss: 1.3203 - accuracy: 0.5248 - val_loss: 1.3472 - val_accuracy: 0.5080\n","Epoch 4/10\n","9000/9000 [==============================] - 55s 6ms/sample - loss: 1.1518 - accuracy: 0.5820 - val_loss: 1.1773 - val_accuracy: 0.5900\n","Epoch 5/10\n","9000/9000 [==============================] - 55s 6ms/sample - loss: 1.0303 - accuracy: 0.6290 - val_loss: 1.1156 - val_accuracy: 0.6090\n","Epoch 6/10\n","9000/9000 [==============================] - 55s 6ms/sample - loss: 0.9044 - accuracy: 0.6783 - val_loss: 1.0242 - val_accuracy: 0.6330\n","Epoch 7/10\n","9000/9000 [==============================] - 57s 6ms/sample - loss: 0.7935 - accuracy: 0.7159 - val_loss: 1.0495 - val_accuracy: 0.6270\n","Epoch 8/10\n","9000/9000 [==============================] - 60s 7ms/sample - loss: 0.6946 - accuracy: 0.7537 - val_loss: 0.9830 - val_accuracy: 0.6790\n","Epoch 9/10\n","9000/9000 [==============================] - 59s 7ms/sample - loss: 0.6193 - accuracy: 0.7803 - val_loss: 0.9794 - val_accuracy: 0.6760\n","Epoch 10/10\n","9000/9000 [==============================] - 56s 6ms/sample - loss: 0.4945 - accuracy: 0.8243 - val_loss: 1.1132 - val_accuracy: 0.6610\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x158e98a2b70>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"G8RcBP2Tf0r8","colab_type":"code","outputId":"66ef1732-7ee6-4185-8853-0c67639bfdd0","colab":{}},"source":["t_labels = np.zeros((len(test_labels), test_labels.max() + 1))\n","for idx, label in enumerate(test_labels):\n","    t_labels[idx, label] = 1 \n","\n","test_loss, test_metrics = model.evaluate(test_images, t_labels, verbose=0) \n","print('test loss', test_loss)\n","print('test metrics', test_metrics)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["test loss 1.060729025363922\n","test metrics 0.676\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gVVkoWIKf0r_","colab_type":"code","colab":{}},"source":["pred = model.predict(test_images)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z98jHDUvf0sD","colab_type":"code","outputId":"ee50c27e-1ed0-4067-c2a3-0688730c1c38","colab":{}},"source":["np.mean(np.argmax(pred, axis=-1) == test_labels)\n","test loss 1.397190655708313\n","test metrics 0.645\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.516"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"cF4jAQLyf0sG","colab_type":"code","outputId":"de6bd6c2-3c96-4b88-dea4-645058253348","colab":{}},"source":["i=6\n","print(labels[i], train_labels[i])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lYmaacyQf0sJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}