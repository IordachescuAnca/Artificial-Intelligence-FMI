{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering - K-means, Hierarchical Clustering, DBSCAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will perform unsupervised classification using clustering algorithms. This will give you an opportunity to explore different clustering methods and different setups for those methods in order to get an intuition as to how the process of performing unsupervised classifiation looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "First, we have our dataset. For this lab we will work with a few categories from the Reuters dataset. The code below will download and preprocess the dataset in order to allow us to spend more time on the actual techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to ./...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('reuters', download_dir = './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous block code downloads the dataset for us. In order to perform the preprocessing step below, we are required to unzip the reuters folder found at './corpora'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = './corpora/reuters'\n",
    "\n",
    "\n",
    "with open(f'{dataset_folder}/cats.txt', 'r') as f:\n",
    "    annotations = f.readlines()\n",
    "    \n",
    "selected_categories = ['sugar', 'livestock', 'jobs', 'ship']\n",
    "category_to_index = dict(zip(selected_categories, range(len(selected_categories))))\n",
    "\n",
    "train_texts, train_labels, test_texts, test_labels = [], [], [], []\n",
    "for ann in annotations:\n",
    "    ann = ann.rstrip().split()\n",
    "    \n",
    "    if not any([category in ann for category in selected_categories]):\n",
    "        continue\n",
    "    \n",
    "    document_text = open(f'{dataset_folder}/{ann[0]}', 'r').read()\n",
    "    label = category_to_index[\n",
    "        [category for category in selected_categories if category in ann[1:]][0]\n",
    "    ]\n",
    "    \n",
    "    if 'train' in ann[0]:\n",
    "        train_texts.append(document_text)\n",
    "        train_labels.append(label)\n",
    "    else:\n",
    "        test_texts.append(document_text)\n",
    "        test_labels.append(label)\n",
    "    \n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this preprocessing we end up with 4 arrays.\n",
    "- train_texts - which is a list of all the texts in the train dataset\n",
    "- train_labels - which is a numpy array with the labels of train_texts, corresponding to the chosen categories\n",
    "- test_texts - which is a list of all the texts in the test dataset\n",
    "- test_labels - which is a numpy array with the labels of test_texts, corresponding to the chosen categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "For this exercise we will use a simple TF-IDF vectorizer from the sklearn library.\n",
    "\n",
    "Your first task is to compute the train_data and test_data variables, which should be the results of applying the TfidfVectorizer from the sklearn library on our dataset. Use a maximum of 500 features. Fit the vectorizer on the training texts and use it to transform both training and test documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 500)\n",
      "(166, 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 500)\n",
    "train_data = vectorizer.fit_transform(train_texts)\n",
    "test_data = vectorizer.transform(test_texts)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** We use only the training data to fit the vectorizer (build the vocabulary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "\n",
    "To ensure that everything is okay with our data and preprocessing, and, in order to have a baseline as a reference, fit an SVC on the training data and evaluate it on the test split. Report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988479262672811\n",
      "0.9457831325301205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(train_data, train_labels)\n",
    "print(np.mean(svc.predict(train_data) == train_labels))\n",
    "print(np.mean(svc.predict(test_data) == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first clustering algorithm we will investigate is the one we've already seen: K-Means.\n",
    "\n",
    "As a basline, fit the a K-Means model, without any change in parameters on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** In otder to have consistency in our results, we will set a random seed for our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 4, random_state = random_state) # we set the seed for the K-means algorithm as well\n",
    "kmeans.fit(train_data)\n",
    "\n",
    "predicted_labels = kmeans.predict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Since we work in an unsupervised classification scenario, we will evaluate or model with respect to the class labels that we have. In order to do that, we have to match each cluster to a class (since clusters are not ordered in any particular order). For that, we will compute the confusion matrix (m\\[i\\]\\[j\\] = number of samples from class i assigned to cluster j) on the training set and use it do determine the best matching.\n",
    "\n",
    "In order to perform the matching we will use the linear_sum_assignment method implemented in the scipy.optimize package (https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.optimize.linear_sum_assignment.html). This method requires a cost function in order to compute the best matching. For that, we will feed the inverse of the confusion matrix, that is 1.0/confusion_matrix.\n",
    "\n",
    "Once you compute the best matching, translate the cluster labels into class labels and evaluate the accuracy of the model on the training set as well as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34101382488479265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9662/3849310271.py:6: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  row_ind, col_ind = linear_sum_assignment(1. / confusion_matrix)\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = np.zeros((4,4))\n",
    "for train_label, predicted_label in zip(train_labels, predicted_labels):\n",
    "    confusion_matrix[train_label][predicted_label] += 1\n",
    "    \n",
    "from scipy.optimize import linear_sum_assignment\n",
    "row_ind, col_ind = linear_sum_assignment(1. / confusion_matrix)\n",
    "\n",
    "translate = dict(zip(col_ind, row_ind))\n",
    "predicted_labels = np.array([\n",
    "    translate[label]\n",
    "    for label in predicted_labels\n",
    "])\n",
    "\n",
    "print(np.mean(predicted_labels == train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** The linear_sum_assignment procedure returns a list of row indices and a list of column indices. In order to perform the matching, we just need to see which row is associated with each column by zipping the vectors. After replacing the cluster values with the class values, we can check our accuracy on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Now, we can evaluate our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28313253012048195\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.array([\n",
    "    translate[label]\n",
    "    for label in kmeans.predict(test_data)\n",
    "])\n",
    "print(np.mean(test_predictions == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises:\n",
    "\n",
    "Make changes such as the following and take note on how those influence the performance of the model.\n",
    "\n",
    "1. Consider the fact that the classes are unbalanced. In order to account for that in the cost matrix, divide each row of the confusion matrix by its sum before passing it to the linear_sum_assignment procedure.\n",
    "2. Insted of passing the inverse of the confusion_matrix as a cost, pass the negative of the confusion matrix\n",
    "3. Try the k-means++ init for the clustering algorithm\n",
    "4. Try different values for the n_init parameter\n",
    "5. Try using PCA or t-sne on your data\n",
    "6. Try using different amount of features when computing the TF-IDF representations\n",
    "7. Try using the stopwords provided with the dataset during the TF-IDF vectorization (nltk_data/corpora/reuters/stopwords)\n",
    "9. Try using a different vectorization procedure\n",
    "10. Try normalizing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** I will showcase a few of these changes and assess their impact on the performance of our model. First I will only build a vocabulary of 100 words, forcing irrelevant tokens out. Secondly, I will use -confusion_matrix instead of 1./confusion_matrix as a cost for the linear_sum_assignment algorithm, in order to avoid dividing by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.619815668202765\n",
      "0.6265060240963856\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 100)\n",
    "train_data = vectorizer.fit_transform(train_texts)\n",
    "test_data = vectorizer.transform(test_texts)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 4, random_state = random_state)\n",
    "kmeans.fit(train_data)\n",
    "\n",
    "predicted_labels = kmeans.predict(train_data)\n",
    "\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "for train_label, predicted_label in zip(train_labels, predicted_labels):\n",
    "    confusion_matrix[train_label][predicted_label] + 1\n",
    "    \n",
    "row_ind, col_ind = linear_sum_assignment(- confusion_matrix)\n",
    "\n",
    "translate = dict(zip(col_ind, row_ind))\n",
    "predicted_labels = np.array([\n",
    "    translate[label]\n",
    "    for label in predicted_labels\n",
    "])\n",
    "\n",
    "print(np.mean(predicted_labels == train_labels))\n",
    "\n",
    "test_predictions = np.array([\n",
    "    translate[label]\n",
    "    for label in kmeans.predict(test_data)\n",
    "])\n",
    "print(np.mean(test_predictions == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** These changes alone got us an improvement of 34.3% on the test set. Let's also try to change the way we compute cluster-class correlations. As we've noticed, the clusters are not balanced, meaning a an overlap of 10 documents between a class and a cluster might mean a lot if the cluster has 20 document in total, and not much if the cluster contains 200 documents. Thus, let us divide each column of the confusion matrix by the sum of the column, that is, for each cluster, divide the number of documents overlapping with each individual class, by the number of documents in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716589861751152\n",
      "0.7048192771084337\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 100)\n",
    "train_data = vectorizer.fit_transform(train_texts)\n",
    "test_data = vectorizer.transform(test_texts)\n",
    "\n",
    "kmeans = KMeans(n_clusters = 4, random_state = 100)\n",
    "kmeans.fit(train_data)\n",
    "\n",
    "predicted_labels = kmeans.predict(train_data)\n",
    "\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "for train_label, predicted_label in zip(train_labels, predicted_labels):\n",
    "    confusion_matrix[train_label][predicted_label] += 1\n",
    "    \n",
    "for col in range(4):\n",
    "    confusion_matrix[:, col] /= np.sum(confusion_matrix[:, col])\n",
    "    \n",
    "row_ind, col_ind = linear_sum_assignment(- confusion_matrix)\n",
    "\n",
    "translate = dict(zip(col_ind, row_ind))\n",
    "predicted_labels = np.array([\n",
    "    translate[label]\n",
    "    for label in predicted_labels\n",
    "])\n",
    "\n",
    "print(np.mean(predicted_labels == train_labels))\n",
    "\n",
    "test_predictions = np.array([\n",
    "    translate[label]\n",
    "    for label in kmeans.predict(test_data)\n",
    "])\n",
    "print(np.mean(test_predictions == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** This change got us an additional 7.8% increase in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider the realistic scenario\n",
    "\n",
    "Consider an actual project where you are given a set of documents collected from the web, that do not have any human annotations. You are tasked to group those documents semantically.\n",
    "\n",
    "Choose one of the models developed in the previous phase.\n",
    "\n",
    "1. Look through the cluster texts in order to get a sense of what each cluster represents.\n",
    "2. For each cluster extract the most important/characteristic words and see what they point to\n",
    "    - you can do this by evaluating documents that are closer to the center of the cluster\n",
    "    - you can do this by running statistics on the entire cluster\n",
    "    - you can use different measures for the importance of a word (number of distinct documents within which the word appears, tfidf for the documents closer to the center, etc)\n",
    "    \n",
    "Use this exercise in order to get a sense of the data and to get a sense of how the clustering algorithm grouped them and what those groups represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** This is a more subjective exercise. Students are encouraged to actually look through this information by hand. For the purposes of this lab, we will only illustrate extracting the most important words out of the entirety of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['export' 'commission' 'year' 'was' 'is' 'from' 'mln' 'at' 'and' 'for'\n",
      " 'said' 'in' 'traders' 'ec' '000' 'of' 'to' 'tonnes' 'the' 'sugar']\n",
      "['from' 'dlrs' 'said' 'japan' 'about' '1986' 'april' 'of' 'at' 'in' 'week'\n",
      " 'to' 'for' 'beef' 'the' 'year' 'and' 'tonnes' '1987' '000']\n",
      "['march' 'tonnes' 'was' '000' 'at' 'and' 'said' 'week' 'year' '1986'\n",
      " 'from' 'of' 'to' 'january' 'february' 'unemployment' 'mln' 'pct' 'in'\n",
      " 'the']\n",
      "['its' 'be' 'strike' 'was' 'port' 'is' 'ships' 'will' 'it' 'that' 'at'\n",
      " 'by' 'on' 'for' 'said' 'in' 'and' 'of' 'to' 'the']\n"
     ]
    }
   ],
   "source": [
    "## sorting the vocabulary words by indexes\n",
    "# print( vectorizer.vocabulary_ )\n",
    "vocab = sorted(list(vectorizer.vocabulary_.items()), key = lambda x: x[1])\n",
    "# print(vocab)\n",
    "vocab = np.array([word for word, index in vocab])\n",
    "\n",
    "\n",
    "for cluster_n in range(4):\n",
    "    cluster_texts = [\n",
    "        train_texts[i]\n",
    "        for i in range(len(train_texts))\n",
    "        if predicted_labels[i] == cluster_n\n",
    "    ]\n",
    "#     print(cluster_texts[0])\n",
    "    \n",
    "    # computing the mean tfidf of the cluster documents\n",
    "    cluster_tfidf = np.array(np.mean(\n",
    "        train_data[predicted_labels == cluster_n], axis = 0\n",
    "    ))[0] # morphing a np.matrix to a numpy array\n",
    "    best_word_indexes = np.argsort(cluster_tfidf)[80:] # getting the top 20 words based on the mean tfidf value\n",
    "    best_words = vocab[best_word_indexes]\n",
    "    print(best_words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** Note the word \"sugar\" as the most importat word of the first cluster. We also notice \"beef\", for the second, \"unemployment\" for the third and \"ships\" for the forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue the investigation of our problem using a different clustering procedure, namely agglomerative clustering. For that we will use the implemenation provided by the scipy library (https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Repeat evaluating the different setups presented in the previous set of exercises in order to investigate the current clustering method. In addition:\n",
    "\n",
    "1. Evaluate different linking methods\n",
    "2. Evaluate different metrics (such as cosine)\n",
    "\n",
    "And see how they impact the performance and learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.toarray() # from scipy sparse matrix to array\n",
    "test_data = test_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576036866359447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "hierarchical = AgglomerativeClustering(n_clusters = 4, linkage = 'complete')\n",
    "predicted_labels = hierarchical.fit_predict(train_data)\n",
    "\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "for train_label, predicted_label in zip(train_labels, predicted_labels):\n",
    "    confusion_matrix[train_label][predicted_label] += 1\n",
    "    \n",
    "for col in range(4):\n",
    "    confusion_matrix[:, col] /= np.sum(confusion_matrix[:, col])\n",
    "    \n",
    "row_ind, col_ind = linear_sum_assignment(- confusion_matrix)\n",
    "\n",
    "translate = dict(zip(col_ind, row_ind))\n",
    "predicted_labels = np.array([\n",
    "    translate[label]\n",
    "    for label in predicted_labels\n",
    "])\n",
    "\n",
    "print(np.mean(predicted_labels == train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** We will evaluate the training performance by replicating the linkage method on the new samples. In our scenario, for a given new sample, we will take each cluster and compute the maximum distance between the new sample and the cluster samples. The cluster closest in terms of the maximum distance will be the one to which the new sample is assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576036866359447\n",
      "0.40963855421686746\n"
     ]
    }
   ],
   "source": [
    "hierarchical = AgglomerativeClustering(n_clusters = 4, linkage = 'complete')\n",
    "predicted_labels = hierarchical.fit_predict(train_data)\n",
    "\n",
    "cluster_samples = dict()\n",
    "for cluster_n in range(4):\n",
    "    cluster_samples[cluster_n] = train_data[predicted_labels == cluster_n] # collecting cluster samples\n",
    "    \n",
    "test_predictions = []\n",
    "for test_sample in test_data:\n",
    "    max_distances = []\n",
    "    for cluster_n in range(4):\n",
    "        distances = np.sum(np.square(cluster_samples[cluster_n] - test_sample), axis = 1) # computing distances towards each cluster sample, similar to the KNN lab\n",
    "        cluster_max_distance = np.max(distances) # getting the maximum distance for the  \"complate\" linkage\n",
    "        max_distances.append(cluster_max_distance)\n",
    "    test_predictions.append(np.argmin(max_distances)) # computing assignment by getting the closest cluster\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "\n",
    "# computing performance\n",
    "confusion_matrix = np.zeros((4,4))\n",
    "for train_label, predicted_label in zip(train_labels, predicted_labels):\n",
    "    confusion_matrix[train_label][predicted_label] += 1\n",
    "    \n",
    "for col in range(4):\n",
    "    confusion_matrix[:, col] /= np.sum(confusion_matrix[:, col])\n",
    "    \n",
    "row_ind, col_ind = linear_sum_assignment(- confusion_matrix)\n",
    "\n",
    "translate = dict(zip(col_ind, row_ind))\n",
    "predicted_labels = np.array([\n",
    "    translate[label]\n",
    "    for label in predicted_labels\n",
    "])\n",
    "\n",
    "print(np.mean(predicted_labels == train_labels))\n",
    "\n",
    "test_predictions = np.array([\n",
    "    translate[label]\n",
    "    for label in test_predictions\n",
    "])\n",
    "print(np.mean(test_predictions == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "Finally, we will make use of the DBSCAN algorithm in order to cluster the data (https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Investigate the DBSCAN model. In addition to the previous setups:\n",
    "\n",
    "1. Evaluate the distribution of distances between samples in the training data and use them as a reference point when deciding the parameters\n",
    "2. Perform a grid search on the parameters\n",
    "3. Use a different association rule for evaluation, which allows multiple clusters to pe assigned to a single class, for instance, based on the confusion matrix, assign each cluster to the class with which it has the most samples in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "distance = np.zeros((len(train_labels), len(train_labels)))\n",
    "for i, train_sample_1 in enumerate(train_data):\n",
    "    for j, train_sample_2 in enumerate(train_data):\n",
    "        distance[i][j] = np.sqrt(np.sum(np.square(train_sample_1 - train_sample_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08713524907467607 1.1305081980945428 1.143984815769202 1.4142135623730954\n"
     ]
    }
   ],
   "source": [
    "print(np.min(distance[distance != 0]), np.mean(distance), np.median(distance), np.max(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.1\n",
      "2 0.14285714285714285\n",
      "2 0.18571428571428572\n",
      "2 0.22857142857142856\n",
      "3 0.27142857142857146\n",
      "3 0.3142857142857143\n",
      "3 0.3571428571428571\n",
      "4 0.4\n",
      "4 0.44285714285714284\n",
      "5 0.48571428571428577\n",
      "5 0.5285714285714286\n",
      "5 0.5714285714285714\n",
      "8 0.6142857142857142\n",
      "9 0.6571428571428571\n",
      "8 0.7\n",
      "6 0.7428571428571429\n",
      "6 0.7857142857142857\n",
      "5 0.8285714285714285\n",
      "3 0.8714285714285714\n",
      "1 0.9142857142857143\n",
      "1 0.9571428571428572\n",
      "1 1.0\n"
     ]
    }
   ],
   "source": [
    "for d in np.linspace(0.1, 1, 22):\n",
    "    dbscan = DBSCAN(eps = d).fit(train_data)\n",
    "    n_clusters = np.max(dbscan.labels_) + 1\n",
    "    print(n_clusters, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** After summarily evaluating the distances and the amount of clusters we can get based on various values for the *eps* parameter, we can perform an evaluation. Let's say we can't obtain the exact amount of clusters we desire. For instance, let's take *eps* = 0.55 and work with our 5 clusters. Naturally, we can assign each new sample from the test set to the closest cluster in term of the minimum distance between the test sample and the cluster samples. Afterwards we can compute our evaluation metric by assigning each cluster to the class with which it has the most documents in common. We can do that by computing the argmax on each column of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542168674698795\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps = 0.55).fit(train_data)\n",
    "predicted_labels = dbscan.labels_\n",
    "n_clusters = np.max(dbscan.labels_) + 1\n",
    "\n",
    "cluster_samples = dict()\n",
    "for cluster_n in range(n_clusters):\n",
    "    cluster_samples[cluster_n] = train_data[predicted_labels == cluster_n]\n",
    "    \n",
    "test_predictions = []\n",
    "for test_sample in test_data:\n",
    "    min_distances = []\n",
    "    for cluster_n in range(n_clusters):\n",
    "        distances = np.sum(np.square(cluster_samples[cluster_n] - test_sample), axis = 1)\n",
    "        cluster_min_distance = np.min(distances)\n",
    "        min_distances.append(cluster_min_distance)\n",
    "    test_predictions.append(np.argmin(min_distances))\n",
    "test_predictions = np.array(test_predictions)\n",
    "\n",
    "\n",
    "confusion_matrix = np.zeros((4, n_clusters))\n",
    "for train_label, predicted_label in zip(train_labels, predicted_labels):\n",
    "    confusion_matrix[train_label][predicted_label] += 1\n",
    "    \n",
    "translate = dict()\n",
    "for i in range(n_clusters):\n",
    "    translate[i] = np.argmax(confusion_matrix[:, i])\n",
    "\n",
    "test_predictions = np.array([\n",
    "    translate[label]\n",
    "    for label in test_predictions\n",
    "])\n",
    "print(np.mean(test_predictions == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** In the end, with our setup, we got a 55.4% performance on the test set, which surpasses the one obtained using the hierarchical clustering method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
