{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbGSaGQ9vIS3"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07IDg6-UvIS6"
      },
      "source": [
        "#### Install NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGzlCrIivIS7",
        "outputId": "07f6692e-b4fb-4d8e-fbd8-4c90ac083410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B58lHrhEvIS9"
      },
      "source": [
        "#### Download models or corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwQRlgElvIS9",
        "outputId": "aa0f22d8-ee96-4640-8a1c-9bed180aa0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 982, in _interactive_download\n",
            "    DownloaderGUI(self).mainloop()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 1226, in __init__\n",
            "    top = self.top = Tk()\n",
            "  File \"/usr/lib/python3.7/tkinter/__init__.py\", line 2023, in __init__\n",
            "    self.tk = _tkinter.create(screenName, baseName, className, interactive, wantobjects, useTk, sync, use)\n",
            "_tkinter.TclError: no display name and no $DISPLAY environment variable\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 2278, in <module>\n",
            "    halt_on_error=options.halt_on_error)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 661, in download\n",
            "    self._interactive_download()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 984, in _interactive_download\n",
            "    DownloaderShell(self).run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\", line 1006, in run\n",
            "    user_input = input('Downloader> ').strip()\n",
            "EOFError: EOF when reading a line\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "#import nltk\n",
        "python -m nltk.downloader # shows a window when graphical output available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvj0wdJmvIS-",
        "outputId": "41e7bf18-4ab6-4558-fe11-f0520365c490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQEsyB5JvITB"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN3HUcBEvIS_"
      },
      "outputs": [],
      "source": [
        "tweet = \"RT @lOR42wsOEFcv3f: I fall too fast, crash too hard, forgive too easily and care too much... :( #amiright\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kl8O_CcvITA"
      },
      "outputs": [],
      "source": [
        "query = 'fast'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFK_-15yvIS9"
      },
      "source": [
        "The naive way..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz3v_jj0vITA",
        "outputId": "1023d2c2-1ee4-46a8-a378-f5d654721206"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tweet.find(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xhFpKFpvITB",
        "outputId": "4aad0a58-307f-431e-8c16-a3a8f56a7304"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@lOR42wsOEFcv3f:',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast,',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard,',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much...',\n",
              " ':(',\n",
              " '#amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tweet.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sx9xgcFvITC",
        "outputId": "78375a93-5679-4e99-eeae-10190a9bc46a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "[query in tweet.split()]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correct tokenization: informed splitting of the text into tokens"
      ],
      "metadata": {
        "id": "gjhBVUZK1LV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoieLiJcvITC",
        "outputId": "393255ee-1792-4a7a-865f-97b79976f293"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@',\n",
              " 'lOR42wsOEFcv3f',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':',\n",
              " '(',\n",
              " '#',\n",
              " 'amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "nltk.word_tokenize(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(\"The U.S.A. is a big country. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC1EysLs0jDL",
        "outputId": "c6822928-25b2-45fd-f526-0c9fd4d82711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'U.S.A.', 'is', 'a', 'big', 'country', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA6xDrMdvITC",
        "outputId": "07f7c4d9-4786-4edc-ea8c-9e371a3390a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[True]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "[query in nltk.word_tokenize(tweet)]\n",
        "# query"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More options..."
      ],
      "metadata": {
        "id": "-KBibnjA1b26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA5qgGixvITD",
        "outputId": "7d84e9b3-ac6d-4626-8445-62cb7f6380b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@',\n",
              " 'lOR42wsOEFcv3f',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':',\n",
              " '(',\n",
              " '#',\n",
              " 'amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "nltk.word_tokenize(tweet, language='spanish')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDcB89vWvITD"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "custom_tokenizer = RegexpTokenizer('[a-zA-Z0-9]+', discard_empty=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbfG3liKvITE",
        "outputId": "d6909fa4-548a-4d11-b580-bf00fd082640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " 'lOR42wsOEFcv3f',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " 'amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "custom_tokenizer.tokenize(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUojQmtRvITE"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm8kis0bvITE",
        "outputId": "d6e852fc-f78c-4799-83bd-f7b796426199"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hellooo', 'how', 'are', 'youu']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tweet_tokenizer.tokenize(tweet)\n",
        "tweet_tokenizer.tokenize(\"helloooooooo how are youu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yltAQxCvITE",
        "outputId": "e3589295-1b99-42fb-a539-24ebb0efdc3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " ':',\n",
              " 'I',\n",
              " 'fall',\n",
              " 'too_fast',\n",
              " ',',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " ',',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(',\n",
              " '#amiright']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "mwe = MWETokenizer()\n",
        "mwe.add_mwe(('too', 'fast'))\n",
        "mwe.tokenize(tweet_tokenizer.tokenize(tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fDVPDRnvITF"
      },
      "outputs": [],
      "source": [
        "mwe.add_mwe((('too', 'fast'), ('too', 'hard')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugIC2npavITF",
        "outputId": "2d358647-fa00-4ac8-8c40-4ef9fb718737"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "query = 'fast'\n",
        "query in mwe.tokenize(tweet_tokenizer.tokenize(tweet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj-5pXTyvITG"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "Counter(nltk.word_tokenize(\"I am so fast. Fast is my name.\".lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JeH_UNm8GOW",
        "outputId": "89b1bfd8-ea6c-4433-b800-24ddf67d0b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'.': 2,\n",
              "         'am': 1,\n",
              "         'fast': 2,\n",
              "         'i': 1,\n",
              "         'is': 1,\n",
              "         'my': 1,\n",
              "         'name': 1,\n",
              "         'so': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bRK61fGevITG",
        "outputId": "084ebd0f-363d-4c3c-aaf5-14eadb7186db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rt @lor42wsoefcv3f: i fall too fast, crash too hard, forgive too easily and care too much... :( #amiright'"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "tweet.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4-6Rnr7vITG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def normalize_tokens(tokenized_text):\n",
        "    # Lowercase\n",
        "    tokens = [t.lower() for t in tokenized_text]\n",
        "    # Remove hashtags\n",
        "    tokens = [t for t in tokens if not t.startswith('#')]\n",
        "    # Remove punctuation\n",
        "    tokens = [t for t in tokens if t not in string.punctuation]\n",
        "    # Keep only letters\n",
        "#     tokens = [t for t in tokens if re.match('^[a-z]+$', t)]\n",
        "    # Normalize characters\n",
        "#     tokens = [re.sub('á', 'a', t) for t in tokens]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BH1VU7zE92Pa",
        "outputId": "4aa36d79-968d-469f-c910-5c8bf0a2b440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR5AUDgevITH",
        "outputId": "fee00347-864e-4de0-8585-120b0607e750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "# normalize_tokens(nltk.word_tokenize(tweet))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edRDrifZvITG",
        "outputId": "6b780268-d642-44f6-af48-a6191ffa568a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['muy', 'rápido']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "spanish_query = 'muy rápido'\n",
        "normalize_tokens(tweet_tokenizer.tokenize(spanish_query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "HFpAR4b_vITH",
        "outputId": "d8f154e3-be3e-4a2f-983e-952385d8e58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 10.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'muy rapido'"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n",
        "unidecode.unidecode(spanish_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLG3Pd4SvITH"
      },
      "source": [
        "#### Uniform normalization principle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "491ipWWuvITH",
        "outputId": "d8fe50a8-abc0-4113-be79-fcc95b5d7fbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['too', 'fast', 'too', 'furious']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "query = 'TOO fast TOO furious'\n",
        "tokenized_query = tweet_tokenizer.tokenize(query)\n",
        "normalized_query = normalize_tokens(tokenized_query)\n",
        "# normalized_query = tokenized_query\n",
        "normalized_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfpl7C7nvITH",
        "outputId": "ae1252e7-75ac-42a4-edf8-5e683cef2f67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "normalized_tweet = normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "# normalized_tweet = normalize_tokens(tweet.split())\n",
        "normalized_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "truJmsHpvITI",
        "outputId": "8ed04986-0619-46be-8feb-9ff7d6cf3192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fast', 'too'}\n",
            "2 common word(s)\n"
          ]
        }
      ],
      "source": [
        "common_words = set(normalized_query).intersection(normalized_tweet)\n",
        "print(common_words)\n",
        "print(len(common_words), \"common word(s)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaLxOlOMvITJ"
      },
      "source": [
        "#### Stemming / Lemmatization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pmCSIy4vITJ"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoXs3q-SvITJ",
        "outputId": "8c3ff9c3-7656-44d4-b401-169181c57081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgiv',\n",
              " 'too',\n",
              " 'easili',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "[stemmer.stem(t) for t in normalized_tweet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.LancasterStemmer() # is prone to overstemming\n",
        "[stemmer.stem(t) for t in normalized_tweet]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mWZSR5d4OuH",
        "outputId": "f5b033f5-3893-413a-ca6f-3d5e944bbdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fal',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forg',\n",
              " 'too',\n",
              " 'easy',\n",
              " 'and',\n",
              " 'car',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxv9vv3TvITK",
        "outputId": "49f51890-98f4-492a-9a02-cae6bafdae54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgiv',\n",
              " 'too',\n",
              " 'easili',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "stemmer = SnowballStemmer(language='english') # Porter2\n",
        "\n",
        "[stemmer.stem(t) for t in normalized_tweet]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer.stem(\"running\"))\n",
        "\n",
        "print(stemmer.stem(\"runs\"))\n",
        "\n",
        "print(stemmer.stem(\"ran\"))\n",
        "\n",
        "print(stemmer.stem(\"darling\"))\n",
        "\n",
        "print(stemmer.stem(\"are\"))\n",
        "\n",
        "print(stemmer.stem(\"bring\"))\n",
        "\n",
        "print(stemmer.stem(\"being\"))\n",
        "\n",
        "print(stemmer.stem(\"Charles\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEDgnkOE4pza",
        "outputId": "8786b4b1-e2cf-4a7e-f45b-15507ef9197c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run\n",
            "run\n",
            "ran\n",
            "darl\n",
            "are\n",
            "bring\n",
            "be\n",
            "charl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1caMRHT7vITK",
        "outputId": "61ba4901-267b-4fa6-cca9-5bdfd7f10444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rt',\n",
              " 'i',\n",
              " 'fall',\n",
              " 'too',\n",
              " 'fast',\n",
              " 'crash',\n",
              " 'too',\n",
              " 'hard',\n",
              " 'forgive',\n",
              " 'too',\n",
              " 'easily',\n",
              " 'and',\n",
              " 'care',\n",
              " 'too',\n",
              " 'much',\n",
              " '...',\n",
              " ':(']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "[lemmatizer.lemmatize(t) for t in normalized_tweet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9yhe4EZvITK",
        "outputId": "b5547bdf-6cd4-4c80-8276-26456f16cec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[('rt', 'NN'), ('i', 'NN'), ('fall', 'VBP'), ('too', 'RB'), ('fast', 'JJ'), ('crash', 'NN'), ('too', 'RB'), ('hard', 'JJ'), ('forgive', 'JJ'), ('too', 'RB'), ('easily', 'RB'), ('and', 'CC'), ('care', 'VB'), ('too', 'RB'), ('much', 'JJ'), ('...', ':'), (':(', 'NN')]\n"
          ]
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "tagged_tweet = nltk.pos_tag(normalized_tweet)\n",
        "print(tagged_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yww_9WdPvITK"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "tag_map = {'J': wn.ADJ, 'V': wn.VERB, 'R': wn.ADV, 'N': wn.NOUN}\n",
        "def get_lemmas(tokenized_text):\n",
        "    tagged_text = nltk.pos_tag(tokenized_text)\n",
        "    return [lemmatizer.lemmatize(w, pos=tag_map.get(p[0], wn.NOUN)) for (w, p) in tagged_text]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwkQvd-SvITL",
        "outputId": "5aacbc1a-bd2f-4d17-e760-efa88ae1a2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'fastest']\n"
          ]
        }
      ],
      "source": [
        "query = \"the fastest!\"\n",
        "normalized_query = normalize_tokens(tweet_tokenizer.tokenize(query))\n",
        "print(normalized_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8AjyEA5vITL",
        "outputId": "ce0aa6f0-41f2-4f80-8c49-66775f6b6aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rt', 'i', 'fall', 'too', 'fast', 'crash', 'too', 'hard', 'forgive', 'too', 'easily', 'and', 'care', 'too', 'much', '...', ':(']\n",
            "['the', 'fast']\n"
          ]
        }
      ],
      "source": [
        "lemmatized_tweet = get_lemmas(normalized_tweet)\n",
        "lemmatized_query = get_lemmas(normalized_query)\n",
        "print(lemmatized_tweet)\n",
        "print(lemmatized_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R08IvRkUvITL",
        "outputId": "a1b74846-db7a-4ddc-aacb-5942c3be1693"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'so', 'fast', 'i', 'am', 'the', 'fastest']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "tweet = \"I am so fast, I am the fastest!\"\n",
        "normalized_tweet = normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "normalized_tweet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[lemmatizer.lemmatize(t) for t in normalized_tweet]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P9ov1TJ67Ml",
        "outputId": "ca17bd4b-d1de-42d8-d8a2-5ed3082810f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'am', 'so', 'fast', 'i', 'am', 'the', 'fastest']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24QRJbnIvITM",
        "outputId": "0c12aa6d-7152-4d54-bda6-8a98956c9bf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'be', 'so', 'fast', 'i', 'be', 'the', 'fast']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "get_lemmas(normalized_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq3JncFSvITL",
        "outputId": "b162a315-c06f-485a-bb56-99e69f1e57b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common words: {'fast'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Common words:\", set(lemmatized_tweet).intersection(set(lemmatized_query)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exJwCbhSvITI"
      },
      "source": [
        "#### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R7abjAkvITI",
        "outputId": "f43c8b61-3922-4127-d80b-9b57fd8631f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu8sWb4vvITI",
        "outputId": "d548fb16-5579-4002-ebfb-954e6544c9a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('romanian')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKxdY7xFFweV",
        "outputId": "a832257e-efed-4795-e999-da2f39abc0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'abia',\n",
              " 'acea',\n",
              " 'aceasta',\n",
              " 'această',\n",
              " 'aceea',\n",
              " 'aceeasi',\n",
              " 'acei',\n",
              " 'aceia',\n",
              " 'acel',\n",
              " 'acela',\n",
              " 'acelasi',\n",
              " 'acele',\n",
              " 'acelea',\n",
              " 'acest',\n",
              " 'acesta',\n",
              " 'aceste',\n",
              " 'acestea',\n",
              " 'acestei',\n",
              " 'acestia',\n",
              " 'acestui',\n",
              " 'aceşti',\n",
              " 'aceştia',\n",
              " 'adica',\n",
              " 'ai',\n",
              " 'aia',\n",
              " 'aibă',\n",
              " 'aici',\n",
              " 'al',\n",
              " 'ala',\n",
              " 'ale',\n",
              " 'alea',\n",
              " 'alt',\n",
              " 'alta',\n",
              " 'altceva',\n",
              " 'altcineva',\n",
              " 'alte',\n",
              " 'altfel',\n",
              " 'alti',\n",
              " 'altii',\n",
              " 'altul',\n",
              " 'am',\n",
              " 'anume',\n",
              " 'apoi',\n",
              " 'ar',\n",
              " 'are',\n",
              " 'as',\n",
              " 'asa',\n",
              " 'asta',\n",
              " 'astea',\n",
              " 'astfel',\n",
              " 'asupra',\n",
              " 'atare',\n",
              " 'atat',\n",
              " 'atata',\n",
              " 'atatea',\n",
              " 'atatia',\n",
              " 'ati',\n",
              " 'atit',\n",
              " 'atita',\n",
              " 'atitea',\n",
              " 'atitia',\n",
              " 'atunci',\n",
              " 'au',\n",
              " 'avea',\n",
              " 'avem',\n",
              " 'aveţi',\n",
              " 'avut',\n",
              " 'aş',\n",
              " 'aţi',\n",
              " 'ba',\n",
              " 'ca',\n",
              " 'cam',\n",
              " 'cand',\n",
              " 'care',\n",
              " 'careia',\n",
              " 'carora',\n",
              " 'caruia',\n",
              " 'cat',\n",
              " 'catre',\n",
              " 'ce',\n",
              " 'cea',\n",
              " 'ceea',\n",
              " 'cei',\n",
              " 'ceilalti',\n",
              " 'cel',\n",
              " 'cele',\n",
              " 'celor',\n",
              " 'ceva',\n",
              " 'chiar',\n",
              " 'ci',\n",
              " 'cind',\n",
              " 'cine',\n",
              " 'cineva',\n",
              " 'cit',\n",
              " 'cita',\n",
              " 'cite',\n",
              " 'citeva',\n",
              " 'citi',\n",
              " 'citiva',\n",
              " 'cu',\n",
              " 'cui',\n",
              " 'cum',\n",
              " 'cumva',\n",
              " 'cât',\n",
              " 'câte',\n",
              " 'câtva',\n",
              " 'câţi',\n",
              " 'cînd',\n",
              " 'cît',\n",
              " 'cîte',\n",
              " 'cîtva',\n",
              " 'cîţi',\n",
              " 'că',\n",
              " 'căci',\n",
              " 'cărei',\n",
              " 'căror',\n",
              " 'cărui',\n",
              " 'către',\n",
              " 'da',\n",
              " 'daca',\n",
              " 'dacă',\n",
              " 'dar',\n",
              " 'dat',\n",
              " 'dată',\n",
              " 'dau',\n",
              " 'de',\n",
              " 'deasupra',\n",
              " 'deci',\n",
              " 'decit',\n",
              " 'deja',\n",
              " 'desi',\n",
              " 'despre',\n",
              " 'deşi',\n",
              " 'din',\n",
              " 'dintr',\n",
              " 'dintr-',\n",
              " 'dintre',\n",
              " 'doar',\n",
              " 'doi',\n",
              " 'doilea',\n",
              " 'două',\n",
              " 'drept',\n",
              " 'dupa',\n",
              " 'după',\n",
              " 'dă',\n",
              " 'e',\n",
              " 'ea',\n",
              " 'ei',\n",
              " 'el',\n",
              " 'ele',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'este',\n",
              " 'eu',\n",
              " 'eşti',\n",
              " 'face',\n",
              " 'fara',\n",
              " 'fata',\n",
              " 'fel',\n",
              " 'fi',\n",
              " 'fie',\n",
              " 'fiecare',\n",
              " 'fii',\n",
              " 'fim',\n",
              " 'fiu',\n",
              " 'fiţi',\n",
              " 'foarte',\n",
              " 'fost',\n",
              " 'fără',\n",
              " 'i',\n",
              " 'ia',\n",
              " 'iar',\n",
              " 'ii',\n",
              " 'il',\n",
              " 'imi',\n",
              " 'in',\n",
              " 'inainte',\n",
              " 'inapoi',\n",
              " 'inca',\n",
              " 'incit',\n",
              " 'insa',\n",
              " 'intr',\n",
              " 'intre',\n",
              " 'isi',\n",
              " 'iti',\n",
              " 'la',\n",
              " 'le',\n",
              " 'li',\n",
              " 'lor',\n",
              " 'lui',\n",
              " 'lângă',\n",
              " 'lîngă',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'mai',\n",
              " 'mea',\n",
              " 'mei',\n",
              " 'mele',\n",
              " 'mereu',\n",
              " 'meu',\n",
              " 'mi',\n",
              " 'mie',\n",
              " 'mine',\n",
              " 'mod',\n",
              " 'mult',\n",
              " 'multa',\n",
              " 'multe',\n",
              " 'multi',\n",
              " 'multă',\n",
              " 'mulţi',\n",
              " 'mâine',\n",
              " 'mîine',\n",
              " 'mă',\n",
              " 'ne',\n",
              " 'ni',\n",
              " 'nici',\n",
              " 'nimeni',\n",
              " 'nimic',\n",
              " 'niste',\n",
              " 'nişte',\n",
              " 'noastre',\n",
              " 'noastră',\n",
              " 'noi',\n",
              " 'nostri',\n",
              " 'nostru',\n",
              " 'nou',\n",
              " 'noua',\n",
              " 'nouă',\n",
              " 'noştri',\n",
              " 'nu',\n",
              " 'numai',\n",
              " 'o',\n",
              " 'or',\n",
              " 'ori',\n",
              " 'oricare',\n",
              " 'orice',\n",
              " 'oricine',\n",
              " 'oricum',\n",
              " 'oricând',\n",
              " 'oricât',\n",
              " 'oricînd',\n",
              " 'oricît',\n",
              " 'oriunde',\n",
              " 'pai',\n",
              " 'parca',\n",
              " 'patra',\n",
              " 'patru',\n",
              " 'pe',\n",
              " 'pentru',\n",
              " 'peste',\n",
              " 'pic',\n",
              " 'pina',\n",
              " 'poate',\n",
              " 'pot',\n",
              " 'prea',\n",
              " 'prima',\n",
              " 'primul',\n",
              " 'prin',\n",
              " 'printr-',\n",
              " 'putini',\n",
              " 'puţin',\n",
              " 'puţina',\n",
              " 'puţină',\n",
              " 'până',\n",
              " 'pînă',\n",
              " 'sa',\n",
              " 'sa-mi',\n",
              " 'sa-ti',\n",
              " 'sai',\n",
              " 'sale',\n",
              " 'sau',\n",
              " 'se',\n",
              " 'si',\n",
              " 'sint',\n",
              " 'sintem',\n",
              " 'spate',\n",
              " 'spre',\n",
              " 'sub',\n",
              " 'sunt',\n",
              " 'suntem',\n",
              " 'sunteţi',\n",
              " 'sus',\n",
              " 'să',\n",
              " 'săi',\n",
              " 'său',\n",
              " 't',\n",
              " 'ta',\n",
              " 'tale',\n",
              " 'te',\n",
              " 'ti',\n",
              " 'tine',\n",
              " 'toata',\n",
              " 'toate',\n",
              " 'toată',\n",
              " 'tocmai',\n",
              " 'tot',\n",
              " 'toti',\n",
              " 'totul',\n",
              " 'totusi',\n",
              " 'totuşi',\n",
              " 'toţi',\n",
              " 'trei',\n",
              " 'treia',\n",
              " 'treilea',\n",
              " 'tu',\n",
              " 'tuturor',\n",
              " 'tăi',\n",
              " 'tău',\n",
              " 'u',\n",
              " 'ul',\n",
              " 'ului',\n",
              " 'un',\n",
              " 'una',\n",
              " 'unde',\n",
              " 'undeva',\n",
              " 'unei',\n",
              " 'uneia',\n",
              " 'unele',\n",
              " 'uneori',\n",
              " 'unii',\n",
              " 'unor',\n",
              " 'unora',\n",
              " 'unu',\n",
              " 'unui',\n",
              " 'unuia',\n",
              " 'unul',\n",
              " 'v',\n",
              " 'va',\n",
              " 'vi',\n",
              " 'voastre',\n",
              " 'voastră',\n",
              " 'voi',\n",
              " 'vom',\n",
              " 'vor',\n",
              " 'vostru',\n",
              " 'vouă',\n",
              " 'voştri',\n",
              " 'vreo',\n",
              " 'vreun',\n",
              " 'vă',\n",
              " 'zi',\n",
              " 'zice',\n",
              " 'îi',\n",
              " 'îl',\n",
              " 'îmi',\n",
              " 'în',\n",
              " 'îţi',\n",
              " 'ăla',\n",
              " 'ălea',\n",
              " 'ăsta',\n",
              " 'ăstea',\n",
              " 'ăştia',\n",
              " 'şi',\n",
              " 'ţi',\n",
              " 'ţie']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNzURg2kvITJ"
      },
      "outputs": [],
      "source": [
        "blacklist_words = stopwords.words('english') + ['rt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-0g081PvITJ",
        "outputId": "a9cdd081-e8e7-4cc2-eea1-e621d604b020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fast', 'fastest']\n"
          ]
        }
      ],
      "source": [
        "cleaned_tweet = [t for t in normalized_tweet if t not in blacklist_words]\n",
        "print(cleaned_tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnD0SkZNvITM"
      },
      "source": [
        "#### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xckCNborvITM",
        "outputId": "e8858809-79dc-4f9e-e424-0ed32ed53873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 2), ('be', 2), ('fast', 2), ('so', 1), ('the', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(get_lemmas(normalized_tweet)).most_common(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOLFMVSFvITM",
        "outputId": "7f23efdb-4e8f-4586-a178-8614c005686e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'be', 'so', 'fast', 'i', 'be', 'the', 'fast']\n"
          ]
        }
      ],
      "source": [
        "tweet = \"I am so fast, I am the fastest!\"\n",
        "normalized_tweet = normalize_tokens(tweet_tokenizer.tokenize(tweet))\n",
        "lemmatized_tweet = get_lemmas(normalized_tweet)\n",
        "print(lemmatized_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR5W_IeqvITM",
        "outputId": "3c29ff62-020f-42e4-a0df-3ac2930e147a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'i': 2, 'am': 2, 'so': 1, 'fast': 1, 'the': 1, 'fastest': 1})\n",
            "Counter({'i': 2, 'be': 2, 'fast': 2, 'so': 1, 'the': 1})\n"
          ]
        }
      ],
      "source": [
        "print(Counter(normalized_tweet))\n",
        "print(Counter(lemmatized_tweet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VIE2dhCvITM"
      },
      "source": [
        "#### Sentence segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDhiS2VGvITN"
      },
      "outputs": [],
      "source": [
        "query = \"I am too fast. I am too furious.\" "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"I am in the U.S.A.\".split(\".\")\n",
        "# query\n",
        "\"I am lazy. He is not in the U.S.A.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AnE2QfLC3iHJ",
        "outputId": "ebee2896-3dfe-4c11-cdc4-ce6ff4b4c37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I am lazy. He is not in the U.S.A.'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPADLll5vITN"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Pp_45fMvITN",
        "outputId": "2e7b02f1-15d4-4321-9aaf-ebdf9bfe613f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I am too fast.', 'I am too furious.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "sent_tokenize(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(\"I am in the U.S.A.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFCCkUkY4Uud",
        "outputId": "08568cde-421a-4d8f-f4dd-b3bb97b8f05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I am in the U.S.A.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rrVvihFvITN",
        "outputId": "726dc4f6-7747-42de-fbf7-606ec2bcb6da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Soy muy rápido!', 'Estoy muy furioso!']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "spanish_tokenizer = nltk.data.load('tokenizers/punkt/PY3/spanish.pickle')\n",
        "spanish_query = 'Soy muy rápido! Estoy muy furioso!'\n",
        "spanish_tokenizer.tokenize(spanish_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PuN1DjvvITN",
        "outputId": "b5165d32-d381-4864-f4f8-86dd64360a63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J.K. Rowling is rich.', 'I am not as rich as J.K.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sent_tokenize(\"J.K. Rowling is rich. I am not as rich as J.K.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJaD2GydvITO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30d9450-104e-4674-cb24-f55b4c9c26ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello!', 'how are you?']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "pkt = PunktSentenceTokenizer()\n",
        "pkt.tokenize(\"hello! how are you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mcm9gIBvITO"
      },
      "source": [
        "#### Numeral conversion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word2number\n",
        "!pip install num2word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuRsqSRbzuDk",
        "outputId": "259d04d6-146b-4932-92b1-ff80e28ca2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word2number in /usr/local/lib/python3.7/dist-packages (1.1)\n",
            "Requirement already satisfied: num2word in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install num2words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A4RLfQcXrGc",
        "outputId": "fdaa1d05-3d1d-4c0b-d220-d9218c1c2843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting num2words\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▎                            | 10 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 101 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "Installing collected packages: num2words\n",
            "Successfully installed num2words-0.5.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "hbn8ybBLvITO",
        "outputId": "4cf0257b-0ca7-4ed3-b786-4dba4b635526"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-756b4009c0e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword2number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mword2number\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mw2n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnum2words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mw2n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eleven\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'num2words'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import word2number\n",
        "from word2number import w2n\n",
        "w2n.word_to_num(\"eleven\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2n.word_to_num(\"twenty three\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpA1EUb5z-CT",
        "outputId": "a19efff9-c8fd-495c-a7c9-ab00f73ed42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "couI08gLvITO",
        "outputId": "ae97f9d8-a8e5-4798-d6b2-b276dfb3b55d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'twelve'"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "from num2words import num2words\n",
        "num2words(12)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num2words(101)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mjtdQ_n60B2a",
        "outputId": "e75e9c6f-2624-4c17-b6f6-5a7808e7e4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one hundred and one'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num2words(2020)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YAK0RUY_0Dnn",
        "outputId": "a98909d1-42a6-4bda-883d-30c5b8924ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'two thousand and twenty'"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2n.word_to_num(\"Twelve o'clock!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCvn9L_W7TDX",
        "outputId": "9294a328-88fb-4b59-ff48-8113514c47f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise"
      ],
      "metadata": {
        "id": "lM4HWS8I_hUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The Environment Ministry’s draft notification to regulate the use of membrane-based water purification systems primarily concerns the manufacturers of reverse osmosis (RO) water filters but effectively bars domestic users from installing RO systems. The notification is the culmination of a legal dispute before the National Green Tribunal, which had banned RO water filter use in Delhi as the purification process wastes water. The association of water filter manufacturers challenged this order and the litigation led to this pan-India notification, where the intent is to conserve water and cut waste. In RO, the total dissolved solids (TDS) in water — which covers trace chemicals, certain viruses, bacteria and salts — can be reduced, to meet potable water standards. Home filters waste nearly 80% of the water during treatment. \""
      ],
      "metadata": {
        "id": "2ZH3K8Q0wGwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize1(text):\n",
        "  text = text.lower()\n",
        "  words = nltk.word_tokenize(text)\n",
        "  stop_words = stopwords.words('english')\n",
        "  words = [word for word in words if word not in stop_words]\n",
        "  return words\n",
        "\n",
        "\n",
        "def normalize2(text):\n",
        "  custom_tokenizer = RegexpTokenizer('[a-zA-Z0-9]+', discard_empty=True)\n",
        "  words = custom_tokenizer.tokenize(text)\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  cleaned_words = []\n",
        "  for word in words:\n",
        "    if word.isdigit():\n",
        "      cleaned_words.append(num2words(word))\n",
        "    else:\n",
        "      cleaned_words.append(lemmatizer.lemmatize(word))\n",
        "  return cleaned_words\n",
        "\n",
        "normalized_words1 = normalize1(text)\n",
        "normalized_words2 = normalize2(text)\n",
        "\n",
        "voc1 = Counter(normalized_words1)\n",
        "print(len(voc1.keys()))\n",
        "print(voc1)\n",
        "\n",
        "voc2 = Counter(normalized_words2)\n",
        "print(len(voc2.keys()))\n",
        "print(voc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P6-nCQ-Unyw",
        "outputId": "0e6b9434-b0e4-46d5-a844-c309575a3a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "Counter({'water': 9, ',': 6, '.': 5, 'ro': 4, 'notification': 3, 'use': 2, 'purification': 2, 'systems': 2, 'manufacturers': 2, '(': 2, ')': 2, 'filters': 2, 'filter': 2, 'waste': 2, '—': 2, 'environment': 1, 'ministry': 1, '’': 1, 'draft': 1, 'regulate': 1, 'membrane-based': 1, 'primarily': 1, 'concerns': 1, 'reverse': 1, 'osmosis': 1, 'effectively': 1, 'bars': 1, 'domestic': 1, 'users': 1, 'installing': 1, 'culmination': 1, 'legal': 1, 'dispute': 1, 'national': 1, 'green': 1, 'tribunal': 1, 'banned': 1, 'delhi': 1, 'process': 1, 'wastes': 1, 'association': 1, 'challenged': 1, 'order': 1, 'litigation': 1, 'led': 1, 'pan-india': 1, 'intent': 1, 'conserve': 1, 'cut': 1, 'total': 1, 'dissolved': 1, 'solids': 1, 'tds': 1, 'covers': 1, 'trace': 1, 'chemicals': 1, 'certain': 1, 'viruses': 1, 'bacteria': 1, 'salts': 1, 'reduced': 1, 'meet': 1, 'potable': 1, 'standards': 1, 'home': 1, 'nearly': 1, '80': 1, '%': 1, 'treatment': 1})\n",
            "82\n",
            "Counter({'the': 9, 'water': 9, 'of': 5, 'to': 4, 'RO': 4, 'filter': 4, 'The': 3, 'notification': 3, 'waste': 3, 'and': 3, 'use': 2, 'purification': 2, 'system': 2, 'manufacturer': 2, 'is': 2, 'a': 2, 'which': 2, 'in': 2, 'this': 2, 'Environment': 1, 'Ministry': 1, 's': 1, 'draft': 1, 'regulate': 1, 'membrane': 1, 'based': 1, 'primarily': 1, 'concern': 1, 'reverse': 1, 'osmosis': 1, 'but': 1, 'effectively': 1, 'bar': 1, 'domestic': 1, 'user': 1, 'from': 1, 'installing': 1, 'culmination': 1, 'legal': 1, 'dispute': 1, 'before': 1, 'National': 1, 'Green': 1, 'Tribunal': 1, 'had': 1, 'banned': 1, 'Delhi': 1, 'process': 1, 'association': 1, 'challenged': 1, 'order': 1, 'litigation': 1, 'led': 1, 'pan': 1, 'India': 1, 'where': 1, 'intent': 1, 'conserve': 1, 'cut': 1, 'In': 1, 'total': 1, 'dissolved': 1, 'solid': 1, 'TDS': 1, 'cover': 1, 'trace': 1, 'chemical': 1, 'certain': 1, 'virus': 1, 'bacteria': 1, 'salt': 1, 'can': 1, 'be': 1, 'reduced': 1, 'meet': 1, 'potable': 1, 'standard': 1, 'Home': 1, 'nearly': 1, 'eighty': 1, 'during': 1, 'treatment': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find a recent news article online.\n",
        "Read it in a python variable (input it manually or read from a file).\n",
        "\n",
        "Write a function that normalizes the text and splits it into tokens. Add flags to customize the different preprocessing choices (which stemmer/lemmatizer to use, whether to lowercase, whether to convert numbers, whether to remove stopwords, ...). \n",
        "\n",
        "Store the vocabulary of unique tokens found in the text.\n",
        "\n",
        "Compare the number of unique tokens (\"types\") with different preprocessing settings."
      ],
      "metadata": {
        "id": "7VJBKi1B_lZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oM7ZdpqXA0l4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ga37tHqo_jqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}