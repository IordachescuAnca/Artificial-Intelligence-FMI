{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iordachescu_Anca_407_P1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fGjVoSE-bYW",
        "outputId": "1cffbc63-0d2e-4c32-ead7-387b10cebe85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymc in /usr/local/lib/python3.7/dist-packages (2.3.8)\n"
          ]
        }
      ],
      "source": [
        "pip install pymc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZSPdpMD-pCA",
        "outputId": "a507ddb5-55f9-4359-a5fd-c830d86cf37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import re\n",
        "import numpy as np\n",
        "import spacy\n",
        "from scipy.stats import wasserstein_distance\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slQclQNT-uzg",
        "outputId": "b959de98-b77e-4c2a-cf5a-4ee332371ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class used for preprocessing the text using spacy library\n",
        "class PreprocessData:\n",
        "  def __init__(self, documents):\n",
        "    #build the dictionary and the features\n",
        "    self.nlp = spacy.load('en_core_web_sm')\n",
        "    self.features = self.build_features(documents)\n",
        "    self.voc = self.build_voc(documents)\n",
        "\n",
        "  def preprocess(self, document):\n",
        "    #preprocessing by eliminating stopwords, punctuation and words that are not alpha\n",
        "    #lowercase\n",
        "    document = document.lower()\n",
        "    doc = self.nlp(document)\n",
        "\n",
        "    preprocessed_words = []\n",
        "\n",
        "    for token in doc:\n",
        "      #eliminate punctuation\n",
        "      if token.is_punct:\n",
        "        continue\n",
        "        #eliminate stop words\n",
        "      if token.is_stop:\n",
        "        continue\n",
        "      word = token.text\n",
        "      if word.isalpha():\n",
        "        #add only alpha words\n",
        "        preprocessed_words.append(token.lemma_)\n",
        "      \n",
        "    return preprocessed_words\n",
        "  \n",
        "  def build_voc(self, documents):\n",
        "    #create a list with unique words from the dataset - vocabulary \n",
        "    voc = []\n",
        "    for doc in documents:\n",
        "      preprocessed_doc = self.preprocess(doc)\n",
        "      for word in preprocessed_doc:\n",
        "        if word not in voc:\n",
        "          voc.append(word)\n",
        "    return voc\n",
        "  \n",
        "  def build_features(self, documents):\n",
        "    #build features based on vocabulary\n",
        "    features = []\n",
        "    for doc in documents:\n",
        "      preprocessed_doc = self.preprocess(doc)\n",
        "      features.append(preprocessed_doc)\n",
        "    \n",
        "    return features\n",
        "\n",
        "\n",
        "  def build_features_encoded(self):\n",
        "    #build features that are encoded by numbers\n",
        "    documents = []\n",
        "    for doc in self.features:\n",
        "      doc_step = []\n",
        "      for word in doc:\n",
        "        doc_step.append(self.voc.index(word))\n",
        "      documents.append(doc_step)\n",
        "    \n",
        "    return documents\n",
        "  \n",
        "  def build_features_new_topic(self, doc):\n",
        "    #preprocessing a new document in order to assign a new topic to it\n",
        "    #select only the words that are already in the vocabulary\n",
        "    #return encoded features\n",
        "    prep_doc = self.preprocess(doc)\n",
        "    features = []\n",
        "    for word in prep_doc:\n",
        "      if word in self.voc:\n",
        "        features.append(self.voc.index(word))\n",
        "    return features\n",
        "                "
      ],
      "metadata": {
        "id": "CktTK2mN--Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LDA(object):\n",
        "    def __init__(self, data, k, a=1, b=1, iter=4000, burnin=None):\n",
        "        #preprocess the documents from the data\n",
        "        #build vocabulary and the features\n",
        "        self.prep = PreprocessData(data)\n",
        "        self.data = self.prep.features\n",
        "        self.vocabulary = self.prep.voc\n",
        "        self.documents =  self.prep.build_features_encoded()\n",
        "\n",
        "\n",
        "        self.K = k #number of topics\n",
        "        self.V = len(self.vocabulary) #len of vocabulary\n",
        "        self.alpha = np.zeros(self.K) + a #self.alpha is a array of number of topics\n",
        "        self.beta = np.zeros(self.V) + b #self.betha is a array of len of vocabulary\n",
        "        \n",
        "        self.M = len(self.data) # number of documents\n",
        "        self.N = [] # lens of each document\n",
        "        for doc in self.data:\n",
        "          self.N.append(len(doc))\n",
        "\n",
        "        self.iter = iter # number iterations\n",
        "        if burnin is None:\n",
        "          self.burnin = self.iter/5 #if user does not provide burinin value, it is equal to iterations/5\n",
        "        else:\n",
        "          self.burnin = burnin\n",
        "        \n",
        "\n",
        "    def compileModel(self):\n",
        "    \n",
        "        #create the variables described in the assignment \n",
        "\n",
        "        #create two lists of Dirichlet and CompletedDirichlet having size equal to size of beta\n",
        "        #we create the both of them because they have to be passed to the pymc model \n",
        "        #we can't pass only the CompletDirichlet because it can't make the right graph for Diriclet\n",
        "        prior_phi = []\n",
        "        phi = []\n",
        "        for k in range(self.K):\n",
        "          aux_prior_phi = pm.Dirichlet(f'prior_phi_{k}', self.beta) \n",
        "          aux_phi = pm.CompletedDirichlet(f'phi_{k}', aux_prior_phi)\n",
        "\n",
        "          prior_phi.append(aux_prior_phi)\n",
        "          phi.append(aux_phi)\n",
        "        \n",
        "        #transform the two lists in containers\n",
        "        self.prior_phi = pm.Container(prior_phi)\n",
        "        self.phi = pm.Container(phi)\n",
        "\n",
        "        #create two lists of Dirichlet and CompletedDirichlet having size equal to size of alpha\n",
        "        #we create the both of them because they have to be passed to the pymc model \n",
        "        #we can't pass only the CompletDirichlet because it can't make the right graph for Diriclet\n",
        "        prior_theta = []\n",
        "        theta = []\n",
        "        for m in range(self.M):\n",
        "          aux_prior_theta = pm.Dirichlet(f'prior_theta_{m}', self.alpha)\n",
        "          aux_theta = pm.CompletedDirichlet(f'theta_{m}', aux_prior_theta) \n",
        "\n",
        "          prior_theta.append(aux_prior_theta)\n",
        "          theta.append(aux_theta)\n",
        "        \n",
        "        #transform the two lists in containers\n",
        "        self.prior_theta = pm.Container(prior_theta)\n",
        "        self.theta = pm.Container(theta)\n",
        "\n",
        "\n",
        "        #for each word create a categorical/multinoulli variable with probability=theta[i][j]\n",
        "        z = []\n",
        "        for m in range(self.M):\n",
        "          z_step = pm.Categorical(f\"z_{m}\", p=self.theta[m], size=self.N[m], value=np.random.randint(self.K, size=self.N[m])) \n",
        "          z.append(z_step)\n",
        "        \n",
        "        #trasnform the list in container\n",
        "        self.z = pm.Container(z)\n",
        "\n",
        "        #for each word(param value - the actual word in the dataset) create a categorical/multinoulli variable with probability=theta[i][j]\n",
        "        #pm.Lambda gets the value phi[z[i][j]]\n",
        "        w = []\n",
        "        for m in range(self.M):\n",
        "          for n in range(self.N[m]):\n",
        "            aux_p = p=pm.Lambda(f\"phi_{m}_{n}\", lambda z=self.z[m][n],phi=self.phi:phi[z])\n",
        "            w_step = pm.Categorical(f\"w_{m}_{n}\", p=aux_p,value=self.documents[m][n], observed=True, verbose=False)\n",
        "            w.append(w_step)\n",
        "\n",
        "        #trasnform the list in container\n",
        "        self.w = pm.Container(w)\n",
        "\n",
        "\n",
        "        #create the model by adding the variables\n",
        "        self.model = pm.Model([self.prior_phi, self.prior_theta, self.phi, self.theta, self.z, self.w])\n",
        "        self.mcmc = pm.MCMC(self.model)\n",
        "        #sampling\n",
        "        self.mcmc.sample(self.iter,self.burnin, thin=1)\n",
        "    \n",
        "    def get_theta_trace(self):\n",
        "      #get theta trace in order to calculate distances for similarity\n",
        "      self.theta_trace = np.array([self.mcmc.trace(f'theta_{m}')[:].squeeze(axis=1) for m in range(self.M)])\n",
        "      self.theta_trace = self.theta_trace.mean(axis=1)\n",
        "      return self.theta_trace\n",
        "    \n",
        "    def similarity_wasserstein(self):\n",
        "      #get theta trace that describes how each document was assigned over the number of topics\n",
        "      theta_trace = self.get_theta_trace()\n",
        "\n",
        "      #calculate distances between every two documents from the corpus\n",
        "      #i used Wasserstein distance which is a metric of the distance between two probability distributions \n",
        "      #showing the cost required to convert one prob distribution to other\n",
        "      distances = []\n",
        "      for i in range(self.M):\n",
        "        aux = []\n",
        "        for j in range(self.M):\n",
        "          dist = wasserstein_distance(theta_trace[i], theta_trace[j])\n",
        "          aux.append(round(dist, 4))\n",
        "        distances.append(aux)\n",
        "\n",
        "      #create dataframe with all costs\n",
        "      df = pd.DataFrame(distances)\n",
        "      return df \n",
        "\n",
        "    def write_theta(self):\n",
        "      #print theta\n",
        "        print('\\nTheta values:')\n",
        "        for m in range(self.M):\n",
        "          theta = self.mcmc.trace(f\"theta_{m}\")[:]\n",
        "          mean_theta = theta.mean(axis = 0)\n",
        "          print(mean_theta)\n",
        "    \n",
        "    def write_phi(self):\n",
        "      #print phi\n",
        "        print('\\nPhi values:')\n",
        "        for k in range(self.K):\n",
        "          phi = self.mcmc.trace(f\"phi_{k}\")[:]\n",
        "          mean_phi = phi.mean(axis=0)\n",
        "          print(mean_phi)\n",
        "  \n",
        "    def write_z(self):\n",
        "      #print z\n",
        "        print('\\nZ values')\n",
        "        for m in range(self.M):\n",
        "          z = self.mcmc.trace(f\"z_{m}\")[:]\n",
        "          mean_z = z.mean(axis=0)\n",
        "          mean_z = np.round(mean_z)\n",
        "          print(mean_z)\n",
        "\n",
        "    \n",
        "    def importantWords(self):\n",
        "      #get the important words for each topic\n",
        "        print()\n",
        "        phi = []\n",
        "        for k in range(self.K):\n",
        "          phi_step = self.mcmc.trace(f\"phi_{k}\")[:]\n",
        "          mean_phi = phi_step.mean(axis=0)\n",
        "          phi.append(mean_phi)\n",
        "        \n",
        "        #create a dictionary of lists for each topic\n",
        "        topics = {}\n",
        "        for k in range(self.K):\n",
        "          topics['topic{}'.format(k)] = []\n",
        "\n",
        "        #get the max value of phi for each word in order to decide the topic it came from\n",
        "        w_topics = np.argmax(phi, axis=0)[0]\n",
        "\n",
        "        #select the words - each word appear in exact one topic\n",
        "        for i in range(len(w_topics)):\n",
        "          topic = w_topics[i]\n",
        "          topics['topic{}'.format(topic)].append(self.vocabulary[i])\n",
        "\n",
        "        print(topics)\n",
        "\n",
        "                \n",
        "    def assignNewTopic(self, document):\n",
        "        \n",
        "        #get the features of the new topic by preprocessing\n",
        "        #unseen words are skipped\n",
        "        features = self.prep.build_features_new_topic(document)\n",
        "        phi = []\n",
        "        for k in range(self.K):\n",
        "          phi_aux = self.mcmc.trace(f\"phi_{k}\")[:].mean(axis=0)\n",
        "          phi.append(phi_aux)\n",
        "\n",
        "        #for each topic we calculate the sum of probabilities of each word\n",
        "        \n",
        "        probs = []\n",
        "        for k in range(self.K):\n",
        "            prob = 0\n",
        "            for i in features:\n",
        "                prob += phi[k][0][i]\n",
        "            probs.append(prob)\n",
        "        \n",
        "        #we get the maximum sum of probabilities as the topic assigned\n",
        "        max_index = np.argsort(probs)[-1]\n",
        "        print(\"The topic of the document is {}\".format(np.argsort(probs)[-1]))"
      ],
      "metadata": {
        "id": "wMU0zXAf_Bf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sanity_set = [\"aaa bbb aaa\",\n",
        "       \"bbb aaa bbb\",\n",
        "        \"aaa bbb bbb aaa\",\n",
        "        \"uuu vvv\",\n",
        "        \"uuu vvv vvv\",\n",
        "        \"uuu vvv vvv uuu\"]\n",
        "\n",
        "\n",
        "lda1 = LDA(data=sanity_set, k=2, a=0.75, b=0.75, iter=5000)\n",
        "lda1.compileModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7I1CnB6_EoY",
        "outputId": "e811e685-e8fd-4372-d11f-ec53efd899ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pymc/MCMC.py:81: UserWarning: Instantiating a Model object directly is deprecated. We recommend passing variables directly to the Model subclass.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [-----------------100%-----------------] 5000 of 5000 complete in 12.0 sec"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda1.vocabulary)\n",
        "print(lda1.documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rtxZs6GBYbt",
        "outputId": "6a015f56-9c1d-4d09-de2d-89361261d7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aaa', 'bbb', 'uuu', 'vvv']\n",
            "[[0, 1, 0], [1, 0, 1], [0, 1, 1, 0], [2, 3], [2, 3, 3], [2, 3, 3, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda1.importantWords()\n",
        "lda1.write_phi()\n",
        "lda1.write_theta()\n",
        "lda1.write_z()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sql0J4b_IXT",
        "outputId": "4816a79c-bbfe-43bb-c118-ed557629ac13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'topic0': ['uuu', 'vvv'], 'topic1': ['aaa', 'bbb']}\n",
            "\n",
            "Phi values:\n",
            "[[0.16281904 0.14961242 0.29643547 0.39113306]]\n",
            "[[0.34412789 0.40397325 0.07798848 0.17391037]]\n",
            "\n",
            "Theta values:\n",
            "[[0.38182754 0.61817246]]\n",
            "[[0.29628673 0.70371327]]\n",
            "[[0.36633143 0.63366857]]\n",
            "[[0.66934224 0.33065776]]\n",
            "[[0.67594053 0.32405947]]\n",
            "[[0.77095658 0.22904342]]\n",
            "\n",
            "Z values\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1.]\n",
            "[1. 1. 1. 1.]\n",
            "[0. 0.]\n",
            "[0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda1.assignNewTopic('vvv aaa vvv ccc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3xpTMX2m7kC",
        "outputId": "abe9e71e-7f49-41de-e93f-272893319e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The topic of the document is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = lda1.similarity_wasserstein()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "rwkZ6iof0cS2",
        "outputId": "d17de142-cee7-4445-8ebc-1ac470a4e447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0855</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0512</td>\n",
              "      <td>0.0578</td>\n",
              "      <td>0.1528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0855</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>0.0344</td>\n",
              "      <td>0.0278</td>\n",
              "      <td>0.0672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.1373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0512</td>\n",
              "      <td>0.0344</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0066</td>\n",
              "      <td>0.1016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0578</td>\n",
              "      <td>0.0278</td>\n",
              "      <td>0.0423</td>\n",
              "      <td>0.0066</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.0672</td>\n",
              "      <td>0.1373</td>\n",
              "      <td>0.1016</td>\n",
              "      <td>0.0950</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0       1       2       3       4       5\n",
              "0  0.0000  0.0855  0.0155  0.0512  0.0578  0.1528\n",
              "1  0.0855  0.0000  0.0700  0.0344  0.0278  0.0672\n",
              "2  0.0155  0.0700  0.0000  0.0357  0.0423  0.1373\n",
              "3  0.0512  0.0344  0.0357  0.0000  0.0066  0.1016\n",
              "4  0.0578  0.0278  0.0423  0.0066  0.0000  0.0950\n",
              "5  0.1528  0.0672  0.1373  0.1016  0.0950  0.0000"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_example = [\"I had a peanuts butter sandwich's for breakfast.\",\n",
        "             \"I like to eat almonds, peanuts and walnuts.\",\n",
        "             \"My neighbor got a little dog yesterday.\",\n",
        "             \"Cats and dogs are mortal enemies.\",\n",
        "             \"You mustnâ€™t feed peanuts to your dog.\"]\n",
        "\n",
        "lda2 = LDA(data=doc_example, k=2, a=0.9, b=0.9, iter=25000)\n",
        "lda2.compileModel()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFYKJfNHghiK",
        "outputId": "f2e5b688-65c0-468f-dfcd-0ec85ed9f69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pymc/MCMC.py:81: UserWarning: Instantiating a Model object directly is deprecated. We recommend passing variables directly to the Model subclass.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [-----------------100%-----------------] 25000 of 25000 complete in 51.6 sec"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda2.importantWords()\n",
        "lda2.write_phi()\n",
        "lda2.write_theta()\n",
        "lda2.write_z()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrDBZQh4hI9Q",
        "outputId": "ba777d18-6086-4f53-abb8-faac6c298053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{'topic0': ['walnut', 'get', 'little', 'dog', 'cat', 'mortal', 'enemy', 'feed'], 'topic1': ['peanut', 'butter', 'sandwich', 'breakfast', 'like', 'eat', 'almond', 'neighbor', 'yesterday']}\n",
            "\n",
            "Phi values:\n",
            "[[0.0668639  0.05130069 0.01135669 0.05811762 0.04728713 0.06002659\n",
            "  0.0001884  0.05770363 0.05373482 0.0737371  0.0500709  0.15043482\n",
            "  0.04290314 0.06772404 0.0974209  0.04807588 0.06305376]]\n",
            "[[0.12948841 0.06748316 0.06976224 0.05889419 0.06169349 0.06792733\n",
            "  0.05769963 0.04168542 0.05512199 0.04819847 0.03933749 0.06626592\n",
            "  0.06449506 0.01091803 0.05551492 0.04567504 0.05983922]]\n",
            "\n",
            "Theta values:\n",
            "[[0.33910173 0.66089827]]\n",
            "[[0.32252454 0.67747546]]\n",
            "[[0.56903778 0.43096222]]\n",
            "[[0.69734108 0.30265892]]\n",
            "[[0.4793777 0.5206223]]\n",
            "\n",
            "Z values\n",
            "[1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "[0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0.]\n",
            "[1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda2.assignNewTopic('I eat two sandwiches at breakfast and play with my dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV0Mli1iqA5M",
        "outputId": "e0f26c68-3829-41d0-9175-566aa59db56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The topic of the document is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['If the skill is being used in practical way, people will consider it a craft instead of art.',\n",
        "          'Likewise, if the design skill is being used in a commercial or industrial way, it may be considered commercial art instead of fine art.',\n",
        "          'It is used to say crafts and design are sometimes considered applied art.',\n",
        "          'Honey bees are known to fly through many chemicals and odors, as is common in insects.',\n",
        "          'A honey bee (also spelled honeybee) is known as a common eusocial flying specie insect within the genus Apis of the bee odors clade.',\n",
        "          'Bees are flying insects closely related to wasps in the case of the best known bee species, the western honey bee, for producing honey.',\n",
        "          'A computer is a modern machine that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming.',\n",
        "          'These programs enable modern computers to perform an extremely wide range of operations that include arithmetic or logical statements.',\n",
        "          'Modern computers have the ability to follow generalized sets of logical operations, called programs in order to carry out a wide number of tasks.'\n",
        "]\n",
        "\n",
        "lda3 = LDA(data=corpus, k=3, a=0.85, b=0.85, iter=15000)\n",
        "lda3.compileModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEpLveH6DjHD",
        "outputId": "e1f8bfbd-af69-4e2e-be0a-57e020c4e683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pymc/MCMC.py:81: UserWarning: Instantiating a Model object directly is deprecated. We recommend passing variables directly to the Model subclass.\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [-----------------100%-----------------] 15000 of 15000 complete in 132.8 sec"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda3.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49IsJ1iOJB5S",
        "outputId": "428ffc98-284e-4d95-e0d8-efc5a12cccb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['skill', 'practical', 'way', 'people', 'consider', 'craft', 'instead', 'art'], ['likewise', 'design', 'skill', 'commercial', 'industrial', 'way', 'consider', 'commercial', 'art', 'instead', 'fine', 'art'], ['craft', 'design', 'consider', 'apply', 'art'], ['honey', 'bee', 'know', 'fly', 'chemical', 'odor', 'common', 'insect'], ['honey', 'bee', 'spell', 'honeybee', 'know', 'common', 'eusocial', 'fly', 'specie', 'insect', 'genus', 'api', 'bee', 'odor', 'clade'], ['bee', 'fly', 'insect', 'closely', 'relate', 'wasp', 'case', 'best', 'know', 'bee', 'specie', 'western', 'honey', 'bee', 'produce', 'honey'], ['computer', 'modern', 'machine', 'instruct', 'carry', 'sequence', 'arithmetic', 'logical', 'operation', 'automatically', 'computer', 'programming'], ['program', 'enable', 'modern', 'computer', 'perform', 'extremely', 'wide', 'range', 'operation', 'include', 'arithmetic', 'logical', 'statement'], ['modern', 'computer', 'ability', 'follow', 'generalized', 'set', 'logical', 'operation', 'call', 'program', 'order', 'carry', 'wide', 'number', 'task']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda3.write_phi()\n",
        "lda3.write_theta()\n",
        "lda3.write_z()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4yzNTluEy6I",
        "outputId": "93715c2d-9467-4f05-83d5-93e249b957fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phi values:\n",
            "[[5.90106361e-02 3.93439747e-03 2.11982605e-02 1.19206203e-02\n",
            "  2.57856536e-03 5.37911582e-03 1.31335028e-03 6.16188457e-04\n",
            "  6.26791375e-03 1.37607411e-02 3.58481711e-03 2.90827523e-03\n",
            "  1.22303657e-02 1.26194886e-02 5.12756166e-02 8.89845046e-04\n",
            "  5.00610228e-02 4.22379632e-02 3.60275933e-02 5.44859983e-02\n",
            "  3.43764588e-02 3.42361720e-02 4.09555389e-02 5.57503235e-02\n",
            "  3.91221304e-02 1.12671560e-02 2.03686040e-02 2.25306474e-02\n",
            "  2.69137996e-02 2.94970562e-02 4.66484749e-04 1.81078183e-02\n",
            "  7.33684311e-03 3.04223021e-02 8.07091305e-03 6.57618456e-03\n",
            "  8.56659160e-05 4.71516834e-03 1.92678718e-02 1.07869110e-02\n",
            "  1.77969350e-02 3.19747279e-03 1.02574841e-02 1.97216471e-02\n",
            "  4.79551759e-04 2.36380882e-02 1.41061639e-02 2.43696584e-03\n",
            "  4.46153223e-03 3.51844179e-03 1.03132752e-02 4.93758253e-03\n",
            "  8.04151950e-03 1.49082097e-03 4.81569379e-03 1.15396742e-02\n",
            "  7.14733302e-05 9.93514028e-03 1.20090027e-02 1.42952434e-03\n",
            "  7.33329505e-03 6.96969644e-04 1.46169209e-02]]\n",
            "[[3.60222954e-02 3.35227214e-02 1.43404834e-02 1.48702869e-02\n",
            "  4.11456946e-02 1.78659066e-03 1.28280352e-02 1.31778722e-02\n",
            "  9.61469867e-03 3.12727058e-02 1.07773056e-02 5.43636583e-04\n",
            "  3.50390639e-03 5.30309251e-03 1.44964438e-02 2.46854882e-02\n",
            "  7.72905020e-03 1.34281728e-02 9.67965725e-03 6.23367237e-03\n",
            "  1.22677875e-02 3.16127275e-04 8.77278270e-03 2.89957734e-03\n",
            "  6.80496933e-03 3.89231023e-02 3.60264518e-03 2.60658195e-03\n",
            "  9.73360541e-04 1.21019307e-03 2.49440160e-02 5.29343381e-03\n",
            "  3.02142597e-02 3.86122454e-02 2.64799428e-02 4.71663067e-05\n",
            "  3.34596670e-02 5.37387992e-02 2.17073562e-02 2.09542243e-02\n",
            "  8.91873071e-03 3.18238606e-02 2.43217265e-02 8.84507590e-03\n",
            "  6.07423651e-02 7.47658402e-03 6.56716438e-03 1.89793232e-02\n",
            "  2.32867374e-02 2.06548538e-02 8.81826034e-03 2.15276306e-02\n",
            "  1.96683060e-02 4.03776332e-03 1.04612794e-05 3.07784446e-02\n",
            "  2.46702433e-03 1.20502008e-02 7.62725784e-04 1.17631566e-02\n",
            "  1.80933731e-02 1.37871838e-03 1.82374652e-02]]\n",
            "[[1.64869277e-02 1.69733045e-02 5.26657336e-02 2.06910370e-02\n",
            "  2.52103331e-03 1.85801820e-02 4.98665990e-02 3.52465114e-02\n",
            "  1.95454526e-02 4.24618019e-03 5.74613325e-02 8.68232837e-03\n",
            "  3.09401409e-02 7.17027168e-03 1.15753317e-02 5.10642255e-03\n",
            "  1.84493043e-03 2.14261855e-02 1.21740983e-02 4.17986748e-04\n",
            "  5.40971143e-03 1.05415175e-03 4.40859344e-05 3.77614097e-03\n",
            "  1.69257480e-02 1.61488081e-02 2.88096533e-03 5.12660527e-04\n",
            "  1.15210450e-02 8.81818875e-03 5.23545728e-03 1.33357144e-02\n",
            "  1.25051092e-02 1.76505675e-02 1.41288378e-03 4.88705872e-03\n",
            "  2.36369395e-02 2.21474211e-02 5.86606711e-03 6.20070037e-03\n",
            "  3.31326404e-03 9.38194738e-03 9.39451012e-03 9.41545017e-04\n",
            "  2.96661813e-03 3.52277838e-02 2.87144403e-03 1.09565175e-02\n",
            "  2.63016611e-02 5.84991649e-03 5.11524870e-03 5.34760629e-02\n",
            "  9.55869849e-03 3.94338607e-02 2.73752910e-02 3.40540301e-03\n",
            "  2.16029772e-02 1.34092482e-02 4.58784894e-02 1.14108131e-02\n",
            "  2.53916637e-02 3.73090532e-02 2.58365683e-02]]\n",
            "\n",
            "Theta values:\n",
            "[[0.12723145 0.37140949 0.50135906]]\n",
            "[[0.12366993 0.20384556 0.67248452]]\n",
            "[[0.07695904 0.51521638 0.40782459]]\n",
            "[[0.71759117 0.18723635 0.09517249]]\n",
            "[[0.71990552 0.18226547 0.09782901]]\n",
            "[[0.43399326 0.45371174 0.11229501]]\n",
            "[[0.21844348 0.64800019 0.13355632]]\n",
            "[[0.09565275 0.53590708 0.36844018]]\n",
            "[[0.14135157 0.4401963  0.41845213]]\n",
            "\n",
            "Z values\n",
            "[1. 1. 2. 1. 1. 2. 2. 2.]\n",
            "[2. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2.]\n",
            "[2. 1. 1. 1. 2.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
            "[1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[1. 1. 1. 1. 1. 1. 2. 1. 1. 2. 1. 1. 2.]\n",
            "[1. 1. 1. 2. 1. 2. 1. 1. 2. 1. 1. 1. 2. 2. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda3.assignNewTopic('The computer I received from my family is great. Now I can do all the arithmetic operations faster for homework')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLXJWV61WHeg",
        "outputId": "2ba5eb0d-cd5d-4f4f-bc97-b23299327965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The topic of the document is 1\n"
          ]
        }
      ]
    }
  ]
}